# 附录 C：参考文献

本附录列出本书编写过程中参考的主要资料。

## 标准与框架

1. OWASP. *OWASP Top 10 for LLM Applications（项目主页）*. https://genai.owasp.org/

2. NIST. (2023). *Artificial Intelligence Risk Management Framework (AI RMF 1.0)*. https://www.nist.gov/itl/ai-risk-management-framework

3. European Union. (2024). *Regulation (EU) 2024/1689 laying down harmonised rules on artificial intelligence (AI Act)*. https://eur-lex.europa.eu/eli/reg/2024/1689/oj

4. MITRE. (2024). *ATLAS (Adversarial Threat Landscape for AI Systems)*. https://atlas.mitre.org/

## 研究论文

### 安全对齐

5. Ouyang, L., et al. (2022). *Training language models to follow instructions with human feedback*. NeurIPS 2022.

6. Bai, Y., et al. (2022). *Constitutional AI: Harmlessness from AI Feedback*. arXiv preprint.

7. Rafailov, R., et al. (2023). *Direct Preference Optimization: Your Language Model is Secretly a Reward Model*. NeurIPS 2023.

### 攻击技术

8. Perez, F., & Ribeiro, I. (2023). *Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of LLMs through a Global Scale Prompt Hacking Competition*. EMNLP 2023. arXiv（检索）: https://arxiv.org/search/?query=Ignore+This+Title+and+HackAPrompt&searchtype=all ; ACL Anthology（检索）: https://aclanthology.org/search/?q=Ignore%20This%20Title%20and%20HackAPrompt

9. Greshake, K., et al. (2023). *Not what you've signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection*. AISec 2023.

10. Zou, A., et al. (2023). *Universal and Transferable Adversarial Attacks on Aligned Language Models*. arXiv preprint.

11. Wei, A., et al. (2023). *Jailbroken: How Does LLM Safety Training Fail?*. NeurIPS 2023.

### 隐私与数据安全

12. Carlini, N., et al. (2021). *Extracting Training Data from Large Language Models*. USENIX Security 2021.

13. Carlini, N., et al. (2023). *Quantifying Memorization Across Neural Language Models*. ICLR 2023.

14. Nasr, M., et al. (2023). *Scalable Extraction of Training Data from (Production) Language Models*. arXiv preprint.

### 模型安全

15. Goldblum, M., et al. (2022). *Dataset Security for Machine Learning: Data Poisoning, Backdoor Attacks, and Defenses*. IEEE TPAMI.

16. Tramèr, F., et al. (2016). *Stealing Machine Learning Models via Prediction APIs*. USENIX Security 2016.

## 技术报告与白皮书

17. OpenAI. (2023). *GPT-4 System Card*. OpenAI Technical Report.

18. Anthropic. (2024). *Claude's Constitution*. Anthropic Research.

19. Google. (2023). *Secure AI Framework (SAIF)*. Google Security Blog.

20. Microsoft. (2024). *Responsible AI Standard, v2*. Microsoft.

## 书籍

21. Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press.

## 补充论文

22. Kurakin, A., Goodfellow, I., & Bengio, S. (2017). *Adversarial examples in the physical world*. ICLR Workshop.

## 行业报告

23. Gartner. (2025). *Hype Cycle for Artificial Intelligence*.

24. McKinsey. (2025). *The State of AI in 2025*.

25. Stanford HAI. (2025). *Artificial Intelligence Index Report 2025*.

## 法规与政策

26. 中华人民共和国国家互联网信息办公室. (2023). *生成式人工智能服务管理暂行办法*.

27. White House. (2023). *Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence*.

28. UK AI Safety Institute. (2024). *International Scientific Report on the Safety of Advanced AI*.

## 在线资源

29. Hugging Face. *Security Documentation*. https://huggingface.co/docs/hub/security

30. LangChain. *Security Best Practices*. https://python.langchain.com/docs/security

31. OpenAI. *Safety & Alignment*. https://openai.com/safety

## 事件通报与监管更新

32. OpenAI. (2023). *March 20 ChatGPT outage: Here's what happened*. https://openai.com/research/march-20-chatgpt-outage

33. The White House. (2025). *Executive Order 14179: Removing Barriers to American Leadership in Artificial Intelligence*. https://www.whitehouse.gov/presidential-actions/2025/01/removing-barriers-to-american-leadership-in-artificial-intelligence/

34. Federal Register. (2025). *Executive Order 14179 filing and revocations*. https://www.federalregister.gov/documents/2025/01/31/2025-02103/removing-barriers-to-american-leadership-in-artificial-intelligence

## 2025-2026 更新补充

35. OWASP. (2025). *Top 10 for LLM Applications 2025*. https://genai.owasp.org/llm-top-10/

36. European Commission. (2025). *Timeline - AI Act implementation timeline*. https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai

37. NIST. (2024). *Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile (NIST AI 600-1)*. https://www.nist.gov/publications/artificial-intelligence-risk-management-framework-generative-artificial-intelligence

38. Model Context Protocol. (2025). *Security Best Practices*. https://modelcontextprotocol.io/specification/2025-06-18/basic/security_best_practices

39. OpenAI. (2025). *New tools and features in the Responses API*（含 MCP 工具支持）. https://openai.com/index/new-tools-and-features-in-the-responses-api/

40. Willison, S. (2023). *Delimiters won't save you from prompt injection*. https://simonwillison.net/2023/May/11/delimiters-wont-save-you/

41. GitHub. (2025). *protectai/rebuff repository page*（标记为 archived）. https://github.com/protectai/rebuff

---

*参考文献截至 2026-02-20（并会随时间变化），后续版本将持续更新。*
